/**
	Kinect Interface
	KinectInterface.cpp
	This class is intended to act as a simplified wrapper for the KinectInteraction gesture-based interactivity from Microsoft's Kinect Developer Toolkit.
	KinectInteraction provides the following high-level features:
		Identification of up to 2 users and identification and tracking of their primary interaction hand.
		Detection services for user's hand location and state.
		Grip and grip release detection.
		Press detection.
		Information on the control targeted by the user.

	KinectInteraction works by pushing information from the Depth Stream and the Skeleton Stream into its own "Interaction Stream"
	In order to process the information the programmer must create a dummy class called the InteractionClient which determines what
	information will be displayed. This is implemented in the CInteractionClient class. The Interaction Stream utilizes this class
	to process the information from the Depth Stream and the Skeleton Stream and determine the raw data for gesture implementation.

	The process is as follows:
		-First the programmer must initialize the sensor
		-Then the Depth Stream and Skeleton Stream can be generated from the sensor
		-Next an Interaction Stream will be generated from the InteractionClient and the sensor
		-Frames are generated from the Depth Stream and the Skeleton Stream
		-They are then passed into the Interaction Stream where the information will be processed
		 and will determine the raw positions of the hands and whether the hand is gripping or pressing.
		-Finally using frames generated by the Interaction Stream, skeletons of the users will be
		 returned and using the raw data gestures can then be utilized for interaction.

	@author Thomas Liao
	@version 1.0
	@date July 20, 2014
*/
#include <iostream>

#include "KinectInterface.h"

#define SafeRelease(X) if(X) delete X;

using namespace std;

KinectInterface::KinectInterface(){}

/*
	This processes the depth stream and passes the information into the InteractionStream
*/
int KinectInterface::processDepth(HANDLE h)
{
	NUI_IMAGE_FRAME pImageFrame;
	INuiFrameTexture* pDepthImagePixelFrame;
	HRESULT hr = m_pNuiSensor->NuiImageStreamGetNextFrame(h, 0, &pImageFrame);
	BOOL nearMode = TRUE;
	m_pNuiSensor->NuiImageFrameGetDepthImagePixelFrameTexture(m_pDepthStreamHandle,
		&pImageFrame,
		&nearMode,
		&pDepthImagePixelFrame);
	INuiFrameTexture * pTexture = pDepthImagePixelFrame;
	NUI_LOCKED_RECT LockedRect;
	pTexture->LockRect(0, &LockedRect, NULL, 0);
	if (LockedRect.Pitch != 0)
	{
		HRESULT hr = m_nuiIStream->ProcessDepth(LockedRect.size,
			PBYTE(LockedRect.pBits),
			pImageFrame.liTimeStamp);
		if (FAILED(hr))
		{
			return -1;
		}
	}
	pTexture->UnlockRect(0);
	m_pNuiSensor->NuiImageStreamReleaseFrame(h, &pImageFrame);
	return 0;
}

/*
	This processes the skeleton stream and passes the information into the InteractionStream
*/
int KinectInterface::processSkeleton()
{
	NUI_SKELETON_FRAME SkeletonFrame = { 0 };
	HRESULT hr = m_pNuiSensor->NuiSkeletonGetNextFrame(0, &SkeletonFrame);
	if (FAILED(hr))
	{
		return -1;
	}

	m_pNuiSensor->NuiTransformSmooth(&SkeletonFrame, NULL);

	Vector4 v;
	m_pNuiSensor->NuiAccelerometerGetCurrentReading(&v);
	hr = m_nuiIStream->ProcessSkeleton(NUI_SKELETON_COUNT,
		SkeletonFrame.SkeletonData,
		&v,
		SkeletonFrame.liTimeStamp);
	if (FAILED(hr))
	{
		return -1;
	}

	return 0;
}

/*
	This processes the interaction stream and updates the list of tracked users
*/
int KinectInterface::processInteraction()
{
	NUI_INTERACTION_FRAME Interaction_Frame;
	m_nuiIStream->GetNextFrame(0, &Interaction_Frame);

	users.clear();
	for (NUI_USER_INFO userInfo:Interaction_Frame.UserInfos)
	{
		if (userInfo.SkeletonTrackingId == 0)
			continue;
		users.emplace_back(userInfo);
	}
	return 0;
}

/*
	This returns the last data about the users stored in the vector.
*/
vector<NUI_USER_INFO> KinectInterface::getUsers(){
	return users;
}

/*
	This is the function that runs */
bool KinectInterface::hasNextFrame()
{
	int nEventIdx;
	nEventIdx = WaitForMultipleObjects(sizeof(hEvents) / sizeof(hEvents[0]), hEvents, FALSE, 100);
	if (WAIT_OBJECT_0 == WaitForSingleObject(m_hEvNuiProcessStop, 0))
	{
		return false;
	}
	// Process signal events
	if (WAIT_OBJECT_0 == WaitForSingleObject(m_hNextDepthFrameEvent, 0))
	{
		processDepth(m_pDepthStreamHandle);
	}
	if (WAIT_OBJECT_0 == WaitForSingleObject(m_hNextSkeletonEvent, 0))
	{
		processSkeleton();
	}
	if (WAIT_OBJECT_0 == WaitForSingleObject(m_hNextInteractionEvent, 0))
	{
		processInteraction();
	}
	return true;
}

/*
	This initializes the Kinect sensor.
*/
HRESULT KinectInterface::ConnectKinect()
{
	INuiSensor * pNuiSensor;
	HRESULT hr;
	int iSensorCount = 0;
	hr = NuiGetSensorCount(&iSensorCount);
	if (FAILED(hr))
	{
		return FAIL_SENSOR_NOT_FOUND;
	}
	// Look at each Kinect sensor
	for (int i = 0; i < iSensorCount; ++i)
	{
		// Create the sensor so we can check status, if we can't create it, move on to the next
		hr = NuiCreateSensorByIndex(i, &pNuiSensor);
		if (FAILED(hr))
		{
			continue;
		}
		// Get the status of the sensor, and if connected, then we can initialize it
		hr = pNuiSensor->NuiStatus();
		if (S_OK == hr)
		{
			m_pNuiSensor = pNuiSensor;
			break;
		}
		// This sensor wasn't OK, so release it since we're not using it
		pNuiSensor->Release();
	}
	if (NULL != m_pNuiSensor)
	{
		if (SUCCEEDED(hr))
		{
			hr = m_pNuiSensor->NuiInitialize(
				NUI_INITIALIZE_FLAG_USES_DEPTH_AND_PLAYER_INDEX |
				NUI_INITIALIZE_FLAG_USES_SKELETON);
			if (hr != S_OK)
			{
				return FAIL_NUI_INIT;
			}

			m_hNextDepthFrameEvent = CreateEvent(NULL, TRUE, FALSE, NULL);
			m_pDepthStreamHandle = NULL;

			hr = m_pNuiSensor->NuiImageStreamOpen(
				NUI_IMAGE_TYPE_DEPTH_AND_PLAYER_INDEX,
				NUI_IMAGE_RESOLUTION_640x480, 0, 2,
				m_hNextDepthFrameEvent, &m_pDepthStreamHandle);
			if (FAILED(hr))
			{
				return FAIL_DEPTH_STREAM;
			}

			m_hNextSkeletonEvent = CreateEvent(NULL, TRUE, FALSE, NULL);
			hr = m_pNuiSensor->NuiSkeletonTrackingEnable(m_hNextSkeletonEvent,
				NUI_SKELETON_TRACKING_FLAG_ENABLE_IN_NEAR_RANGE);
			if (FAILED(hr))
			{
				return FAIL_SKELE_STREAM;
			}
		}
	}
	if (NULL == m_pNuiSensor || FAILED(hr))
	{
		return FAIL_SENSOR_NOT_FOUND;
	}
	return OKAY;
}

/*
	Initialize 
*/
int KinectInterface::init(){
	HRESULT sensorStatus = ConnectKinect();
	if(FAILED(sensorStatus))
		return sensorStatus;
	HRESULT hr;
	m_hNextInteractionEvent = CreateEvent(NULL, TRUE, FALSE, NULL);
	m_hEvNuiProcessStop = CreateEvent(NULL, TRUE, FALSE, NULL);
	hr = NuiCreateInteractionStream(m_pNuiSensor,
		(INuiInteractionClient *)&m_nuiIClient,
		&m_nuiIStream);
	if (FAILED(hr))
	{
		return FAIL_INTERACTION_STREAM;
	}
	hr = NuiCreateInteractionStream(m_pNuiSensor,0,&m_nuiIStream);
	hr = m_nuiIStream->Enable(m_hNextInteractionEvent);
	if (FAILED(hr))
	{
		return FAIL_INTERACTION_STREAM;
	}

	cout << "Initialization successful!" << endl;
	return 0;
}

/*
	
*/
int KinectInterface::close(){
	CloseHandle(m_hEvNuiProcessStop);
	m_hEvNuiProcessStop = NULL;
	CloseHandle(m_hNextSkeletonEvent);
	CloseHandle(m_hNextDepthFrameEvent);
	CloseHandle(m_hNextInteractionEvent);

	m_pNuiSensor->NuiShutdown();
	SafeRelease(m_pNuiSensor);
	return 0;
}